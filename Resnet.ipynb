{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RRCh_kzCKBk",
        "outputId": "48d7cd56-f25e-45ef-a03b-b7885be4e2b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs) (6.0.1)\n",
            "Installing collected packages: yacs\n",
            "Successfully installed yacs-0.1.8\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.16.0-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.16.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6\n",
            "Collecting hexbytes\n",
            "  Downloading hexbytes-1.0.0-py3-none-any.whl (5.9 kB)\n",
            "Installing collected packages: hexbytes\n",
            "Successfully installed hexbytes-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo\n",
        "!pip install datasets\n",
        "!pip install hexbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torchinfo import summary\n",
        "from datasets import load_dataset\n",
        "from torchvision import transforms\n",
        "from argparse import ArgumentParser\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.functional import normalize\n",
        "from sklearn.metrics import accuracy_score\n",
        "from hexbytes import HexBytes"
      ],
      "metadata": {
        "id": "VzXRL08k67-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]"
      ],
      "metadata": {
        "id": "rhKeTPRi67kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAFE_IDX = 4 # the index of safe smart contract\n",
        "\n",
        "def __get_RGB_image(bytecode):\n",
        "    image = np.frombuffer(bytecode, dtype=np.uint8)\n",
        "    length = int(math.ceil(len(image)/3))\n",
        "    image = np.pad(image, pad_width=(0, length*3 - len(image)))\n",
        "    image = image.reshape((-1, 3))\n",
        "    sqrt_len = int(math.ceil(math.sqrt(image.shape[0])))\n",
        "    image = np.pad(image,  pad_width=((0, sqrt_len**2 - image.shape[0]),(0,0)))\n",
        "    image = image.reshape((sqrt_len, sqrt_len, 3))\n",
        "    image = Image.fromarray(image)\n",
        "    return image\n",
        "\n",
        "def __get_one_hot_encoded_label(label):\n",
        "    one_hot = np.zeros(5)\n",
        "    for elem in label:\n",
        "        if elem < SAFE_IDX:\n",
        "            one_hot[elem] = 1\n",
        "        elif elem > SAFE_IDX:\n",
        "            one_hot[elem-1] = 1\n",
        "    return one_hot\n",
        "\n",
        "def generate_image_and_label(example):\n",
        "    code = HexBytes(example['bytecode'])\n",
        "    example['image'] = __get_RGB_image(code)\n",
        "    example['label'] = __get_one_hot_encoded_label(example['slither'])\n",
        "    return example"
      ],
      "metadata": {
        "id": "B1tjNHiY67hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torchvision import models\n",
        "\n",
        "class ResNetModel(nn.Module):\n",
        "    def __init__(self, num_classes=5, classify=True):\n",
        "        super(ResNetModel, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "\n",
        "        if classify:\n",
        "            self.resnet.fc = nn.Linear(512, num_classes)\n",
        "        else:\n",
        "            features = nn.ModuleList(self.resnet.children())[:-1]\n",
        "            self.resnet = nn.Sequential(*features).append(nn.Flatten())\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.resnet(inputs)\n",
        "\n",
        "    def get_layer_groups(self):\n",
        "        linear_layers = [elem[1] for elem in filter(lambda param_tuple: 'fc' in param_tuple[0], self.resnet.named_parameters())]\n",
        "        other_layers = [elem[1] for elem in filter(lambda param_tuple: 'fc' not in param_tuple[0], self.resnet.named_parameters())]\n",
        "        param_groups = {\n",
        "            'classifier': linear_layers,\n",
        "            'feature_extractor': other_layers\n",
        "        }\n",
        "        return param_groups"
      ],
      "metadata": {
        "id": "7E61b4Ol67d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "metrics = {'acc': accuracy_score}\n",
        "\n",
        "def initialize_logs_dict(loader_train, loader_val):\n",
        "    logs = {\n",
        "        'epoch_num': 0,\n",
        "        'train_batches_per_epoch': len(loader_train),\n",
        "        'val_batches_per_epoch': len(loader_val) if loader_val is not None else None,\n",
        "        'train': {'loss': 0.0, 'predictions': [], 'labels': [], 'batch_idx': 0},\n",
        "        'val': {'loss': 0.0, 'predictions': [], 'labels': [], 'batch_idx': 0},\n",
        "        'metrics': {'train_acc': 0.0} | {'val_' + metric: 0.0 for metric in metrics.keys()}\n",
        "    }\n",
        "    return logs\n",
        "\n",
        "def run_epoch(model, criterion, optimizer, data_loader, device, mode, logs):\n",
        "    model.train() if mode == 'train' else model.eval()\n",
        "    total_loss = 0.0\n",
        "    running_metrics = {metric: 0.0 for metric in metrics.keys()}\n",
        "    pbar = tqdm(data_loader, desc=f'{mode.capitalize()}ing...')\n",
        "\n",
        "    for data in pbar:\n",
        "        images, labels = data['image'].to(device), data['label'].to(device)\n",
        "\n",
        "        with torch.set_grad_enabled(mode == 'train'):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = (outputs >= 0.0).float()\n",
        "            logs[mode]['predictions'] += preds.tolist()\n",
        "            logs[mode]['labels'] += labels.tolist()\n",
        "            logs[mode]['loss'] = total_loss / (logs[mode]['batch_idx'] + 1)\n",
        "\n",
        "            for metric_name, metric_func in metrics.items():\n",
        "                running_metrics[metric_name] += metric_func(labels.tolist(), preds.tolist())\n",
        "                logs['metrics'][mode + '_' + metric_name] = running_metrics[metric_name] / (logs[mode]['batch_idx'] + 1)\n",
        "\n",
        "            logs[mode]['batch_idx'] += 1\n",
        "            pbar.set_postfix({'loss': logs[mode]['loss'], **{metric_name: logs['metrics'][mode + '_' + metric_name] for metric_name in metrics.keys()}})\n",
        "\n",
        "            if mode == 'train':\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "def main_training_loop(model, criterion, optimizer, loader_train, loader_val, device, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        print(f'Epoch {epoch}:')\n",
        "        logs = initialize_logs_dict(loader_train, loader_val)\n",
        "        logs['epoch_num'] = epoch\n",
        "\n",
        "        run_epoch(model, criterion, optimizer, loader_train, device, 'train', logs)\n",
        "        run_epoch(model, criterion, optimizer, loader_val, device, 'val', logs)\n",
        "\n",
        "        print('train_loss: {:.4f} | val_loss: {:.4f} |'.format(logs['train']['loss'], logs['val']['loss']), end=' ')\n",
        "        print(\" | \".join(['{}: {:.4f}'.format(metric_name, metric_val) for metric_name, metric_val in logs['metrics'].items()]), end='\\n\\n')\n",
        "\n",
        "    run_epoch(model, criterion, optimizer, loader_test, device, 'val', logs)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8Vb9lGZp67aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "whitelist_weight_modules = (torch.nn.Linear, torch.nn.Conv1d, torch.nn.Conv2d, nn.LSTM)\n",
        "blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.BatchNorm1d, torch.nn.BatchNorm2d, nn.Embedding)\n",
        "\n",
        "def get_weight_decay_params(model):\n",
        "    \"\"\" Adapted from the implementation at https://github.com/karpathy/minGPT/blob/3ed14b2cec0dfdad3f4b2831f2b4a86d11aef150/mingpt/model.py#L136\"\"\"\n",
        "    decay = set()\n",
        "    no_decay = set()\n",
        "    for module_name, module in model.named_modules():\n",
        "        for param_name, _ in module.named_parameters():\n",
        "            fpn = '%s.%s' % (module_name, param_name) if module_name else param_name # full param name\n",
        "\n",
        "            if 'bias' in param_name:\n",
        "                # all biases will not be decayed\n",
        "                no_decay.add(fpn)\n",
        "            elif 'weight' in param_name and isinstance(module, whitelist_weight_modules):\n",
        "                # weights of whitelist modules will be weight decayed\n",
        "                decay.add(fpn)\n",
        "            elif 'weight' in param_name and isinstance(module, blacklist_weight_modules):\n",
        "                # weights of blacklist modules will NOT be weight decayed\n",
        "                no_decay.add(fpn)\n",
        "\n",
        "    # validate that we considered every parameter\n",
        "    param_dict = {pn: p for pn, p in model.named_parameters()}\n",
        "    inter_params = decay & no_decay\n",
        "    union_params = decay | no_decay\n",
        "    assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n",
        "    assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n",
        "                                                % (str(param_dict.keys() - union_params), )\n",
        "\n",
        "    decay =  [param_dict[pn] for pn in sorted(list(decay))]\n",
        "    no_decay =  [param_dict[pn] for pn in sorted(list(no_decay))]\n",
        "\n",
        "    return decay, no_decay"
      ],
      "metadata": {
        "id": "q20TS4PE67W6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_ds = load_dataset(\"mwritescode/slither-audited-smart-contracts\", 'big-multilabel', split='train', ignore_verifications=True)\n",
        "val_ds = load_dataset(\"mwritescode/slither-audited-smart-contracts\", 'big-multilabel', split='validation', ignore_verifications=True)\n",
        "\n",
        "\n",
        "train_ds = train_ds.filter(lambda elem: elem['bytecode'] != '0x')\n",
        "val_ds = val_ds.filter(lambda elem: elem['bytecode'] != '0x')\n",
        "\n",
        "map_func = generate_image_and_label\n",
        "train_ds = train_ds.map(map_func, remove_columns=['address', 'source_code', 'bytecode', 'slither'])\n",
        "val_ds = val_ds.map(map_func, remove_columns=['address', 'source_code', 'bytecode', 'slither'])\n",
        "\n",
        "max_len = 512\n",
        "\n",
        "img_size = 224\n",
        "mean, std = IMAGENET_MEAN, IMAGENET_STD\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.CenterCrop(img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std),\n",
        "])\n",
        "\n",
        "padding_val = 0\n",
        "\n",
        "def img_label_to_tensor(examples):\n",
        "    if 'image' in examples.keys():\n",
        "        examples['image'] = [img_transform(elem) for elem in examples['image']]\n",
        "    if 'label' in examples.keys():\n",
        "        examples['label'] = torch.tensor(examples['label'])\n",
        "        return examples\n",
        "\n",
        "train_ds.set_transform(img_label_to_tensor)\n",
        "val_ds.set_transform(img_label_to_tensor)\n",
        "\n",
        "pos_weights = None\n",
        "\n",
        "num_cls = 5\n",
        "model_name = 'resnet'\n",
        "\n",
        "model = ResNetModel(num_classes=num_cls)\n",
        "model = model.to('cuda')\n",
        "\n",
        "TRAIN_FROM_SCRATCH = False\n",
        "if not TRAIN_FROM_SCRATCH:\n",
        "    param_groups = model.get_layer_groups()\n",
        "    for param in param_groups['feature_extractor'][:-6]:\n",
        "        param.requires_grad = False\n",
        "\n",
        "summary(model)\n",
        "print(model)\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "loader_train = DataLoader(train_ds,\n",
        "                    batch_size=batch_size,\n",
        "                    drop_last=True,\n",
        "                    shuffle=True)\n",
        "loader_val = DataLoader(val_ds,\n",
        "                    batch_size=batch_size,\n",
        "                    drop_last=True,\n",
        "                    shuffle=False)\n",
        "\n",
        "# trainer = Trainer(model=model, train_dataloader=loader_train, val_dataloader=loader_val, train_helper=train_heper)\n",
        "\n",
        "decay, no_decay = get_weight_decay_params(model)\n",
        "optim_groups = [\n",
        "    {'params': decay, 'weight_decay': 0.0001},\n",
        "    {'params': no_decay, 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = optim.SGD(\n",
        "        optim_groups,\n",
        "        lr=TRAIN_FROM_SCRATCH,\n",
        "        momentum=0.9,\n",
        "        nesterov=True)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
        "\n",
        "# trainer.compile(loss=criterion, optimizer=optimizer, metrics={'acc': accuracy_score})\n",
        "\n",
        "callbacks = []\n",
        "device = 'cuda'\n",
        "epochs= 20\n",
        "main_training_loop(model, criterion, optimizer, loader_train, loader_val, device, epochs)\n",
        "\n",
        "# if cfg.TRAINING.TRACK_METRICS.USE:\n",
        "#     metrics = {}\n",
        "#     for avg in cfg.TRAINING.TRACK_METRICS.AVERAGE:\n",
        "#         print(avg)\n",
        "#         metrics.update({avg + '_' + metric: REGISTRY[metric](average=avg, labels=np.arange(0, num_cls)) for metric in cfg.TRAINING.TRACK_METRICS.NAMES})\n",
        "#     callbacks.append(MetricsCallback(metrics=metrics))\n",
        "\n",
        "# if cfg.TRAINING.LOGGER.USE:\n",
        "#     add_to_logging = [] if not cfg.TRAINING.TRACK_METRICS.USE else metrics.keys()\n",
        "#     callbacks.append(TensorBoardLogger(\n",
        "#         track_epochwise=['loss', 'acc', *add_to_logging],\n",
        "#         run_tag=cfg.TRAINING.LOGGER.RUN_TAG))\n",
        "\n",
        "# if cfg.TRAINING.EARLY_STOPPING.USE:\n",
        "#     callbacks.append(EarlyStopper(\n",
        "#         model=model,\n",
        "#         metric_name=cfg.TRAINING.EARLY_STOPPING.MONITOR,\n",
        "#         decreasing=cfg.TRAINING.EARLY_STOPPING.DECREASING,\n",
        "#         restore_best_weights=True,\n",
        "#         patience=cfg.TRAINING.EARLY_STOPPING.PATIENCE))\n",
        "\n",
        "\n",
        "# if cfg.TRAINING.CHECKPOINTS.USE:\n",
        "#     callbacks.append(CheckpointSaver(\n",
        "#         model=model,\n",
        "#         optimizer=optimizer,\n",
        "#         monitor=cfg.TRAINING.CHECKPOINTS.MONITOR,\n",
        "#         decreasing=cfg.TRAINING.CHECKPOINTS.DECREASING,\n",
        "#         path=cfg.TRAINING.CHECKPOINTS.PATH))\n",
        "\n",
        "# trainer.fit(epochs=cfg.TRAINING.N_EPOCHS, callbacks=callbacks)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ql5rWM9t67TK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RbWR0R6Z67Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lEzcYPzn7WA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "icE4oAXT7V9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wnn3m8yV7V5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YnR1BlWMBl6X"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torchinfo import summary\n",
        "from datasets import load_dataset\n",
        "from torchvision import transforms\n",
        "from argparse import ArgumentParser\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.functional import normalize\n",
        "from sklearn.metrics import accuracy_score\n",
        "from hexbytes import HexBytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]"
      ],
      "metadata": {
        "id": "ji-rfQ-enBQz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yacs.config import CfgNode as ConfigurationNode\n",
        "\n",
        "# YACS overwrite these settings using YAML\n",
        "__C = ConfigurationNode()\n",
        "\n",
        "__C.MODEL = ConfigurationNode()\n",
        "__C.MODEL.NAME = 'resnet' # ADD MODEl CONFIGURATIONS AS THE CODING PROGRESSES\n",
        "__C.MODEL.N_CLASSES = 5\n",
        "\n",
        "__C.DATASET = ConfigurationNode()\n",
        "__C.DATASET.RGB_IMAGES = True\n",
        "__C.DATASET.IMG_SHAPE = 224\n",
        "__C.DATASET.USE_IMAGENET_STATS = True\n",
        "__C.DATASET.AUGUMENTATION = False\n",
        "__C.DATASET.BINARY_LABELS = False\n",
        "__C.DATASET.NORMALIZE = True\n",
        "__C.DATASET.MAX_SEQ_LEN = 512\n",
        "\n",
        "__C.DATASET.LOADER = ConfigurationNode()\n",
        "__C.DATASET.LOADER.BATCH_SIZE = 16\n",
        "\n",
        "__C.TRAINING = ConfigurationNode()\n",
        "__C.TRAINING.N_EPOCHS = 100\n",
        "__C.TRAINING.TRAIN_FROM_SCRATCH = False\n",
        "__C.TRAINING.LAYERS_TO_FINETUNE = 6\n",
        "__C.TRAINING.LOSS = 'binary_crossentropy'\n",
        "\n",
        "__C.TRAINING.OPTIMIZER = ConfigurationNode()\n",
        "__C.TRAINING.OPTIMIZER.NAME = 'sgd'\n",
        "__C.TRAINING.OPTIMIZER.LR = 1e-3\n",
        "__C.TRAINING.OPTIMIZER.WEIGHT_DECAY = 0.0001\n",
        "__C.TRAINING.OPTIMIZER.MOMENTUM = 0.9\n",
        "__C.TRAINING.OPTIMIZER.USE_WEIGHTS = False\n",
        "\n",
        "__C.TRAINING.EARLY_STOPPING = ConfigurationNode()\n",
        "__C.TRAINING.EARLY_STOPPING.USE = True\n",
        "__C.TRAINING.EARLY_STOPPING.MONITOR = 'val_acc'\n",
        "__C.TRAINING.EARLY_STOPPING.DECREASING = False\n",
        "__C.TRAINING.EARLY_STOPPING.PATIENCE = 10\n",
        "\n",
        "__C.TRAINING.CHECKPOINTS = ConfigurationNode()\n",
        "__C.TRAINING.CHECKPOINTS.USE = True\n",
        "__C.TRAINING.CHECKPOINTS.MONITOR = 'val_acc'\n",
        "__C.TRAINING.CHECKPOINTS.DECREASING = False\n",
        "__C.TRAINING.CHECKPOINTS.PATH = 'checkpoints/<config_name>.pkl'\n",
        "\n",
        "__C.TRAINING.LOGGER = ConfigurationNode()\n",
        "__C.TRAINING.LOGGER.USE = True\n",
        "__C.TRAINING.LOGGER.RUN_TAG = '<config_name>'\n",
        "\n",
        "__C.TRAINING.TRACK_METRICS = ConfigurationNode()\n",
        "__C.TRAINING.TRACK_METRICS.USE = True\n",
        "__C.TRAINING.TRACK_METRICS.NAMES = ('f1', 'precision', 'recall')\n",
        "__C.TRAINING.TRACK_METRICS.AVERAGE = ['macro', 'micro'] #Optionally change to/add micro and weighted\n",
        "\n",
        "def get_cfg_defaults():\n",
        "    \"\"\"\n",
        "    Get a yacs CfgNode object with default values\n",
        "    \"\"\"\n",
        "    # Return a clone so that the defaults will not be altered\n",
        "    # It will be subsequently overwritten with local YAML.\n",
        "    return __C.clone()"
      ],
      "metadata": {
        "id": "cmq00SBro7pL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAFE_IDX = 4 # the index of safe smart contract\n",
        "\n",
        "def __get_RGB_image(bytecode):\n",
        "    image = np.frombuffer(bytecode, dtype=np.uint8)\n",
        "    length = int(math.ceil(len(image)/3))\n",
        "    image = np.pad(image, pad_width=(0, length*3 - len(image)))\n",
        "    image = image.reshape((-1, 3))\n",
        "    sqrt_len = int(math.ceil(math.sqrt(image.shape[0])))\n",
        "    image = np.pad(image,  pad_width=((0, sqrt_len**2 - image.shape[0]),(0,0)))\n",
        "    image = image.reshape((sqrt_len, sqrt_len, 3))\n",
        "    image = Image.fromarray(image)\n",
        "    return image\n",
        "\n",
        "def __get_one_hot_encoded_label(label):\n",
        "    one_hot = np.zeros(5)\n",
        "    for elem in label:\n",
        "        if elem < SAFE_IDX:\n",
        "            one_hot[elem] = 1\n",
        "        elif elem > SAFE_IDX:\n",
        "            one_hot[elem-1] = 1\n",
        "    return one_hot\n",
        "\n",
        "def generate_image_and_label(example):\n",
        "    code = HexBytes(example['bytecode'])\n",
        "    example['image'] = __get_RGB_image(code)\n",
        "    example['label'] = __get_one_hot_encoded_label(example['slither'])\n",
        "    return example"
      ],
      "metadata": {
        "id": "z281m517pU5z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class GetMeanStd:\n",
        "    \"\"\"\n",
        "    Inspired by the implementation of https://github.com/Nikronic/CoarseNet/blob/master/utils/preprocess.py#L142-L200\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, batch_size, img_size):\n",
        "        self.img_transform =transforms.Compose([\n",
        "        transforms.Resize(img_size),\n",
        "        transforms.CenterCrop(img_size),\n",
        "        transforms.ToTensor()])\n",
        "\n",
        "        dataset.set_transform(self.__to_tensor)\n",
        "        self.data_loader = DataLoader(dataset=dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=False,\n",
        "                            num_workers=0,\n",
        "                            pin_memory=0)\n",
        "\n",
        "    def __to_tensor(self, examples):\n",
        "        examples['image'] = [self.img_transform(elem) for elem in examples['image']]\n",
        "        return examples\n",
        "\n",
        "    def __call__(self):\n",
        "        mean = 0.\n",
        "        std = 0.\n",
        "        nb_samples = 0.\n",
        "        for data in tqdm.tqdm(self.data_loader, desc='Computing stats..'):\n",
        "            data = data['image']\n",
        "            batch_samples = data.size(0)\n",
        "            data = data.view(batch_samples, data.size(1), -1)\n",
        "            mean += data.mean(2).sum(0)\n",
        "            std += data.std(2).sum(0)\n",
        "            nb_samples += batch_samples\n",
        "\n",
        "        mean /= nb_samples\n",
        "        std /= nb_samples\n",
        "\n",
        "        return mean, std"
      ],
      "metadata": {
        "id": "d-YPy28jqOvR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torchvision import models\n",
        "\n",
        "class ResNetModel(nn.Module):\n",
        "    def __init__(self, num_classes=5, classify=True):\n",
        "        super(ResNetModel, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "\n",
        "        if classify:\n",
        "            self.resnet.fc = nn.Linear(512, num_classes)\n",
        "        else:\n",
        "            features = nn.ModuleList(self.resnet.children())[:-1]\n",
        "            self.resnet = nn.Sequential(*features).append(nn.Flatten())\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.resnet(inputs)\n",
        "\n",
        "    def get_layer_groups(self):\n",
        "        linear_layers = [elem[1] for elem in filter(lambda param_tuple: 'fc' in param_tuple[0], self.resnet.named_parameters())]\n",
        "        other_layers = [elem[1] for elem in filter(lambda param_tuple: 'fc' not in param_tuple[0], self.resnet.named_parameters())]\n",
        "        param_groups = {\n",
        "            'classifier': linear_layers,\n",
        "            'feature_extractor': other_layers\n",
        "        }\n",
        "        return param_groups"
      ],
      "metadata": {
        "id": "X2F5phn5pth7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "metrics = {'acc': accuracy_score}\n",
        "\n",
        "def initialize_logs_dict(loader_train, loader_val):\n",
        "    logs = {\n",
        "        'epoch_num': 0,\n",
        "        'train_batches_per_epoch': len(loader_train),\n",
        "        'val_batches_per_epoch': len(loader_val) if loader_val is not None else None,\n",
        "        'train': {'loss': 0.0, 'predictions': [], 'labels': [], 'batch_idx': 0},\n",
        "        'val': {'loss': 0.0, 'predictions': [], 'labels': [], 'batch_idx': 0},\n",
        "        'metrics': {'train_acc': 0.0} | {'val_' + metric: 0.0 for metric in metrics.keys()}\n",
        "    }\n",
        "    return logs\n",
        "\n",
        "def run_epoch(model, criterion, optimizer, data_loader, device, mode, logs):\n",
        "    model.train() if mode == 'train' else model.eval()\n",
        "    total_loss = 0.0\n",
        "    running_metrics = {metric: 0.0 for metric in metrics.keys()}\n",
        "    pbar = tqdm(data_loader, desc=f'{mode.capitalize()}ing...')\n",
        "\n",
        "    for data in pbar:\n",
        "        images, labels = data['image'].to(device), data['label'].to(device)\n",
        "\n",
        "        with torch.set_grad_enabled(mode == 'train'):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = (outputs >= 0.0).float()\n",
        "            logs[mode]['predictions'] += preds.tolist()\n",
        "            logs[mode]['labels'] += labels.tolist()\n",
        "            logs[mode]['loss'] = total_loss / (logs[mode]['batch_idx'] + 1)\n",
        "\n",
        "            for metric_name, metric_func in metrics.items():\n",
        "                running_metrics[metric_name] += metric_func(labels.tolist(), preds.tolist())\n",
        "                logs['metrics'][mode + '_' + metric_name] = running_metrics[metric_name] / (logs[mode]['batch_idx'] + 1)\n",
        "\n",
        "            logs[mode]['batch_idx'] += 1\n",
        "            pbar.set_postfix({'loss': logs[mode]['loss'], **{metric_name: logs['metrics'][mode + '_' + metric_name] for metric_name in metrics.keys()}})\n",
        "\n",
        "            if mode == 'train':\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "def main_training_loop(model, criterion, optimizer, loader_train, loader_val, device, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        print(f'Epoch {epoch}:')\n",
        "        logs = initialize_logs_dict(loader_train, loader_val)\n",
        "        logs['epoch_num'] = epoch\n",
        "\n",
        "        run_epoch(model, criterion, optimizer, loader_train, device, 'train', logs)\n",
        "        run_epoch(model, criterion, optimizer, loader_val, device, 'val', logs)\n",
        "\n",
        "        print('train_loss: {:.4f} | val_loss: {:.4f} |'.format(logs['train']['loss'], logs['val']['loss']), end=' ')\n",
        "        print(\" | \".join(['{}: {:.4f}'.format(metric_name, metric_val) for metric_name, metric_val in logs['metrics'].items()]), end='\\n\\n')\n",
        "\n",
        "    run_epoch(model, criterion, optimizer, loader_test, device, 'val', logs)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zQtbX8AGtMzf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torchinfo import summary\n",
        "from datasets import load_dataset\n",
        "from torchvision import transforms\n",
        "from argparse import ArgumentParser\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.functional import normalize\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "whitelist_weight_modules = (torch.nn.Linear, torch.nn.Conv1d, torch.nn.Conv2d, nn.LSTM)\n",
        "blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.BatchNorm1d, torch.nn.BatchNorm2d, nn.Embedding)\n",
        "\n",
        "def get_weight_decay_params(model):\n",
        "    \"\"\" Adapted from the implementation at https://github.com/karpathy/minGPT/blob/3ed14b2cec0dfdad3f4b2831f2b4a86d11aef150/mingpt/model.py#L136\"\"\"\n",
        "    decay = set()\n",
        "    no_decay = set()\n",
        "    for module_name, module in model.named_modules():\n",
        "        for param_name, _ in module.named_parameters():\n",
        "            fpn = '%s.%s' % (module_name, param_name) if module_name else param_name # full param name\n",
        "\n",
        "            if 'bias' in param_name:\n",
        "                # all biases will not be decayed\n",
        "                no_decay.add(fpn)\n",
        "            elif 'weight' in param_name and isinstance(module, whitelist_weight_modules):\n",
        "                # weights of whitelist modules will be weight decayed\n",
        "                decay.add(fpn)\n",
        "            elif 'weight' in param_name and isinstance(module, blacklist_weight_modules):\n",
        "                # weights of blacklist modules will NOT be weight decayed\n",
        "                no_decay.add(fpn)\n",
        "\n",
        "    # validate that we considered every parameter\n",
        "    param_dict = {pn: p for pn, p in model.named_parameters()}\n",
        "    inter_params = decay & no_decay\n",
        "    union_params = decay | no_decay\n",
        "    assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n",
        "    assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n",
        "                                                % (str(param_dict.keys() - union_params), )\n",
        "\n",
        "    decay =  [param_dict[pn] for pn in sorted(list(decay))]\n",
        "    no_decay =  [param_dict[pn] for pn in sorted(list(no_decay))]\n",
        "\n",
        "    return decay, no_decay\n",
        "\n",
        "\n",
        "def train_pipeline(path):\n",
        "    train_ds = load_dataset(\"mwritescode/slither-audited-smart-contracts\", 'big-multilabel', split='train', ignore_verifications=True)\n",
        "    val_ds = load_dataset(\"mwritescode/slither-audited-smart-contracts\", 'big-multilabel', split='validation', ignore_verifications=True)\n",
        "\n",
        "\n",
        "    train_ds = train_ds.filter(lambda elem: elem['bytecode'] != '0x')\n",
        "    val_ds = val_ds.filter(lambda elem: elem['bytecode'] != '0x')\n",
        "\n",
        "    CFG_PATH = path\n",
        "\n",
        "    cfg = get_cfg_defaults()\n",
        "    cfg.merge_from_file(CFG_PATH)\n",
        "    cfg.freeze()\n",
        "\n",
        "    map_func = generate_image_and_label\n",
        "    train_ds = train_ds.map(map_func, remove_columns=['address', 'source_code', 'bytecode', 'slither'])\n",
        "    val_ds = val_ds.map(map_func, remove_columns=['address', 'source_code', 'bytecode', 'slither'])\n",
        "\n",
        "    max_len = 512\n",
        "\n",
        "    img_size = 224\n",
        "    mean, std = IMAGENET_MEAN, IMAGENET_STD\n",
        "    img_transform = transforms.Compose([\n",
        "        transforms.Resize(img_size),\n",
        "        transforms.CenterCrop(img_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std),\n",
        "    ])\n",
        "\n",
        "    padding_val = 0\n",
        "\n",
        "    def img_label_to_tensor(examples):\n",
        "        if 'image' in examples.keys():\n",
        "            examples['image'] = [img_transform(elem) for elem in examples['image']]\n",
        "        if 'label' in examples.keys():\n",
        "            examples['label'] = torch.tensor(examples['label'])\n",
        "            return examples\n",
        "\n",
        "    train_ds.set_transform(img_label_to_tensor)\n",
        "    val_ds.set_transform(img_label_to_tensor)\n",
        "\n",
        "    pos_weights = None\n",
        "\n",
        "    num_cls = 5\n",
        "    model_name = 'resnet'\n",
        "\n",
        "    model = ResNetModel(num_classes=num_cls)\n",
        "    model = model.to('cuda')\n",
        "    # train_heper = REGISTRY['inception_train_helper'] if 'inception' in model_name else REGISTRY['default_train_helper']\n",
        "    TRAIN_FROM_SCRATCH = False\n",
        "    if not TRAIN_FROM_SCRATCH:\n",
        "        param_groups = model.get_layer_groups()\n",
        "        for param in param_groups['feature_extractor'][:-6]:\n",
        "            param.requires_grad = False\n",
        "\n",
        "    summary(model)\n",
        "    print(model)\n",
        "\n",
        "    batch_size = 16\n",
        "\n",
        "    loader_train = DataLoader(train_ds,\n",
        "                        batch_size=batch_size,\n",
        "                        drop_last=True,\n",
        "                        shuffle=True)\n",
        "    loader_val = DataLoader(val_ds,\n",
        "                        batch_size=batch_size,\n",
        "                        drop_last=True,\n",
        "                        shuffle=False)\n",
        "\n",
        "    # trainer = Trainer(model=model, train_dataloader=loader_train, val_dataloader=loader_val, train_helper=train_heper)\n",
        "\n",
        "    decay, no_decay = get_weight_decay_params(model)\n",
        "    optim_groups = [\n",
        "        {'params': decay, 'weight_decay': 0.0001},\n",
        "        {'params': no_decay, 'weight_decay': 0.0}\n",
        "    ]\n",
        "\n",
        "    optimizer = optim.SGD(\n",
        "            optim_groups,\n",
        "            lr=TRAIN_FROM_SCRATCH,\n",
        "            momentum=0.9,\n",
        "            nesterov=True)\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
        "\n",
        "    # trainer.compile(loss=criterion, optimizer=optimizer, metrics={'acc': accuracy_score})\n",
        "\n",
        "    callbacks = []\n",
        "    device = 'cuda'\n",
        "    epochs= 20\n",
        "    main_training_loop(model, criterion, optimizer, loader_train, loader_val, device, epochs)\n",
        "\n",
        "    # if cfg.TRAINING.TRACK_METRICS.USE:\n",
        "    #     metrics = {}\n",
        "    #     for avg in cfg.TRAINING.TRACK_METRICS.AVERAGE:\n",
        "    #         print(avg)\n",
        "    #         metrics.update({avg + '_' + metric: REGISTRY[metric](average=avg, labels=np.arange(0, num_cls)) for metric in cfg.TRAINING.TRACK_METRICS.NAMES})\n",
        "    #     callbacks.append(MetricsCallback(metrics=metrics))\n",
        "\n",
        "    # if cfg.TRAINING.LOGGER.USE:\n",
        "    #     add_to_logging = [] if not cfg.TRAINING.TRACK_METRICS.USE else metrics.keys()\n",
        "    #     callbacks.append(TensorBoardLogger(\n",
        "    #         track_epochwise=['loss', 'acc', *add_to_logging],\n",
        "    #         run_tag=cfg.TRAINING.LOGGER.RUN_TAG))\n",
        "\n",
        "    # if cfg.TRAINING.EARLY_STOPPING.USE:\n",
        "    #     callbacks.append(EarlyStopper(\n",
        "    #         model=model,\n",
        "    #         metric_name=cfg.TRAINING.EARLY_STOPPING.MONITOR,\n",
        "    #         decreasing=cfg.TRAINING.EARLY_STOPPING.DECREASING,\n",
        "    #         restore_best_weights=True,\n",
        "    #         patience=cfg.TRAINING.EARLY_STOPPING.PATIENCE))\n",
        "\n",
        "\n",
        "    # if cfg.TRAINING.CHECKPOINTS.USE:\n",
        "    #     callbacks.append(CheckpointSaver(\n",
        "    #         model=model,\n",
        "    #         optimizer=optimizer,\n",
        "    #         monitor=cfg.TRAINING.CHECKPOINTS.MONITOR,\n",
        "    #         decreasing=cfg.TRAINING.CHECKPOINTS.DECREASING,\n",
        "    #         path=cfg.TRAINING.CHECKPOINTS.PATH))\n",
        "\n",
        "    # trainer.fit(epochs=cfg.TRAINING.N_EPOCHS, callbacks=callbacks)\n",
        "\n",
        "\n",
        "train_pipeline('./default.yaml')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c4K7WLq8nH7q",
        "outputId": "e9d7ea73-0fc4-4100-999c-a4b806c35a32"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:2487: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'verification_mode=no_checks' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1429: FutureWarning: The repository for mwritescode/slither-audited-smart-contracts contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mwritescode/slither-audited-smart-contracts\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNetModel(\n",
            "  (resnet): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=512, out_features=5, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoch 0:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training...:  23%|██▎       | 1136/4963 [01:11<04:01, 15.83it/s, loss=0.698, acc=0.0307]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-4826c22684a8>\u001b[0m in \u001b[0;36m<cell line: 178>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m \u001b[0mtrain_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./default.yaml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-4826c22684a8>\u001b[0m in \u001b[0;36mtrain_pipeline\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mmain_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# if cfg.TRAINING.TRACK_METRICS.USE:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-eef0242da32c>\u001b[0m in \u001b[0;36mmain_training_loop\u001b[0;34m(model, criterion, optimizer, loader_train, loader_val, device, epochs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch_num'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-eef0242da32c>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(model, criterion, optimizer, data_loader, device, mode, logs)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{mode.capitalize()}ing...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# The mapping type may not support `__init__(iterable)`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# The mapping type may not support `__init__(iterable)`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "C1-PoT0bs3J3",
        "outputId": "199e6a60-ccd6-496f-e85e-bd35e78b9e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-a87813ffe34d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tz_EtAfJs3VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AynLvzHhs3Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS8QHYZlCIv7",
        "outputId": "15d12939-3733-4e1d-86d6-0f66ce8081ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:2487: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'verification_mode=no_checks' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1429: FutureWarning: The repository for mwritescode/slither-audited-smart-contracts contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mwritescode/slither-audited-smart-contracts\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_ds = load_dataset(\"mwritescode/slither-audited-smart-contracts\", 'big-multilabel', split='train', ignore_verifications=True)\n",
        "val_ds = load_dataset(\"mwritescode/slither-audited-smart-contracts\", 'big-multilabel', split='validation', ignore_verifications=True)\n",
        "test_ds = load_dataset(\"mwritescode/slither-audited-smart-contracts\", 'big-multilabel', split='test', ignore_verifications=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHtjlOY4CzQC"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.filter(lambda elem: elem['bytecode'] != '0x')\n",
        "val_ds = val_ds.filter(lambda elem: elem['bytecode'] != '0x')\n",
        "test_ds = test_ds.filter(lambda elem: elem['bytecode'] != '0x')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQRsx746EH3D"
      },
      "outputs": [],
      "source": [
        "SAFE_IDX = 4 # the index of safe smart contract\n",
        "\n",
        "def __get_RGB_image(bytecode):\n",
        "    image = np.frombuffer(bytecode, dtype=np.uint8)\n",
        "    length = int(math.ceil(len(image)/3))\n",
        "    image = np.pad(image, pad_width=(0, length*3 - len(image)))\n",
        "    image = image.reshape((-1, 3))\n",
        "    sqrt_len = int(math.ceil(math.sqrt(image.shape[0])))\n",
        "    image = np.pad(image,  pad_width=((0, sqrt_len**2 - image.shape[0]),(0,0)))\n",
        "    image = image.reshape((sqrt_len, sqrt_len, 3))\n",
        "    image = Image.fromarray(image)\n",
        "    return image\n",
        "\n",
        "def __get_one_hot_encoded_label(label):\n",
        "    one_hot = np.zeros(5)\n",
        "    for elem in label:\n",
        "        if elem < SAFE_IDX:\n",
        "            one_hot[elem] = 1\n",
        "        elif elem > SAFE_IDX:\n",
        "            one_hot[elem-1] = 1\n",
        "    return one_hot\n",
        "\n",
        "def generate_image_and_label(example):\n",
        "    code = HexBytes(example['bytecode'])\n",
        "    example['image'] = __get_RGB_image(code)\n",
        "    example['label'] = __get_one_hot_encoded_label(example['slither'])\n",
        "    return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEQzlgUCC4eG"
      },
      "outputs": [],
      "source": [
        "map_func = generate_image_and_label\n",
        "\n",
        "train_ds = train_ds.map(map_func, remove_columns=['address', 'source_code', 'bytecode', 'slither'])\n",
        "val_ds = val_ds.map(map_func, remove_columns=['address', 'source_code', 'bytecode', 'slither'])\n",
        "test_ds = test_ds.map(map_func, remove_columns=['address', 'source_code', 'bytecode', 'slither'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mb3CQQAHEiog"
      },
      "outputs": [],
      "source": [
        "max_len = 512\n",
        "padding_val = 0\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "def img_label_to_tensor(examples):\n",
        "\n",
        "  img_size = 224\n",
        "  mean, std = IMAGENET_MEAN, IMAGENET_STD\n",
        "  img_transform = transforms.Compose([\n",
        "            transforms.Resize(img_size),\n",
        "            transforms.CenterCrop(img_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=mean, std=std),\n",
        "        ])\n",
        "  if 'image' in examples.keys():\n",
        "      examples['image'] = [img_transform(elem) for elem in examples['image']]\n",
        "  if 'image' in examples.keys():\n",
        "      examples['image'] = [np.pad(img, pad_width=(0, max_len - len(img)), constant_values=padding_val) if len(img) < max_len else img[:max_len] for img in examples['image']]\n",
        "      examples['image'] = [torch.tensor(img) for img in examples['image']]\n",
        "  if 'label' in examples.keys():\n",
        "      examples['label'] = torch.tensor(examples['label'])\n",
        "      return examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuNCSFm_FTHh"
      },
      "outputs": [],
      "source": [
        "train_ds.set_transform(img_label_to_tensor)\n",
        "val_ds.set_transform(img_label_to_tensor)\n",
        "test_ds.set_transform(img_label_to_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YukXmQEFb3_"
      },
      "outputs": [],
      "source": [
        "model_name = 'resnet'\n",
        "num_cls = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prp2TgO5FhdS"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "\n",
        "loader_train = DataLoader(train_ds,\n",
        "                    batch_size=batch_size,\n",
        "                    drop_last=True,\n",
        "                    shuffle=True)\n",
        "loader_val = DataLoader(val_ds,\n",
        "                    batch_size=batch_size,\n",
        "                    drop_last=True,\n",
        "                    shuffle=False)\n",
        "loader_test = DataLoader(test_ds,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "et8LFetZVofV"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torchvision import models\n",
        "\n",
        "class ResNetModel(nn.Module):\n",
        "    def __init__(self, num_classes=5, classify=True):\n",
        "        super(ResNetModel, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "\n",
        "        if classify:\n",
        "            self.resnet.fc = nn.Linear(512, num_classes)\n",
        "        else:\n",
        "            features = nn.ModuleList(self.resnet.children())[:-1]\n",
        "            self.resnet = nn.Sequential(*features).append(nn.Flatten())\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.resnet(inputs)\n",
        "\n",
        "    def get_layer_groups(self):\n",
        "        linear_layers = [elem[1] for elem in filter(lambda param_tuple: 'fc' in param_tuple[0], self.resnet.named_parameters())]\n",
        "        other_layers = [elem[1] for elem in filter(lambda param_tuple: 'fc' not in param_tuple[0], self.resnet.named_parameters())]\n",
        "        param_groups = {\n",
        "            'classifier': linear_layers,\n",
        "            'feature_extractor': other_layers\n",
        "        }\n",
        "        return param_groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYhWNUDKEr2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea2763b-ddff-4e7f-c7b9-f684dd304ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "model = ResNetModel(num_classes=num_cls)\n",
        "model = model.to('cuda')\n",
        "\n",
        "whitelist_weight_modules = (torch.nn.Linear, torch.nn.Conv1d, torch.nn.Conv2d, nn.LSTM)\n",
        "blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.BatchNorm1d, torch.nn.BatchNorm2d, nn.Embedding)\n",
        "\n",
        "def get_weight_decay_params(model):\n",
        "    \"\"\" Adapted from the implementation at https://github.com/karpathy/minGPT/blob/3ed14b2cec0dfdad3f4b2831f2b4a86d11aef150/mingpt/model.py#L136\"\"\"\n",
        "    decay = set()\n",
        "    no_decay = set()\n",
        "    for module_name, module in model.named_modules():\n",
        "        for param_name, _ in module.named_parameters():\n",
        "            fpn = '%s.%s' % (module_name, param_name) if module_name else param_name # full param name\n",
        "\n",
        "            if 'bias' in param_name:\n",
        "                # all biases will not be decayed\n",
        "                no_decay.add(fpn)\n",
        "            elif 'weight' in param_name and isinstance(module, whitelist_weight_modules):\n",
        "                # weights of whitelist modules will be weight decayed\n",
        "                decay.add(fpn)\n",
        "            elif 'weight' in param_name and isinstance(module, blacklist_weight_modules):\n",
        "                # weights of blacklist modules will NOT be weight decayed\n",
        "                no_decay.add(fpn)\n",
        "        # validate that we considered every parameter\n",
        "    param_dict = {pn: p for pn, p in model.named_parameters()}\n",
        "    inter_params = decay & no_decay\n",
        "    union_params = decay | no_decay\n",
        "    assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n",
        "    assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n",
        "                                                % (str(param_dict.keys() - union_params), )\n",
        "\n",
        "    decay =  [param_dict[pn] for pn in sorted(list(decay))]\n",
        "    no_decay =  [param_dict[pn] for pn in sorted(list(no_decay))]\n",
        "\n",
        "    return decay, no_decay\n",
        "\n",
        "decay, no_decay = get_weight_decay_params(model)\n",
        "optim_groups = [\n",
        "        {'params': decay, 'weight_decay': 0.0001},\n",
        "        {'params': no_decay, 'weight_decay': 0.0}\n",
        "    ]\n",
        "\n",
        "optimizer = optimizer = optim.SGD(\n",
        "            optim_groups,\n",
        "            lr=1e-3,\n",
        "            momentum=0.9,\n",
        "            nesterov=True)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xfxNXE_VpEz"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "4uJr4oVlWCx2",
        "outputId": "b0fe4fce-55a2-4d63-8d36-09d01160d357"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-797dd39aa677>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mmain_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "metrics = {'acc': accuracy_score, 'f1': f1_score, 'precision': precision_score, 'recall': recall_score}\n",
        "\n",
        "def initialize_logs_dict(loader_train, loader_val):\n",
        "    logs = {\n",
        "        'epoch_num': 0,\n",
        "        'train_batches_per_epoch': len(loader_train),\n",
        "        'val_batches_per_epoch': len(loader_val) if loader_val is not None else None,\n",
        "        'train': {'loss': 0.0, 'predictions': [], 'labels': [], 'batch_idx': 0},\n",
        "        'val': {'loss': 0.0, 'predictions': [], 'labels': [], 'batch_idx': 0},\n",
        "        'metrics': {'train_acc': 0.0} | {'val_' + metric: 0.0 for metric in metrics.keys()}\n",
        "    }\n",
        "    return logs\n",
        "\n",
        "def run_epoch(model, criterion, optimizer, data_loader, device, mode, logs):\n",
        "    model.train() if mode == 'train' else model.eval()\n",
        "    total_loss = 0.0\n",
        "    running_metrics = {metric: 0.0 for metric in metrics.keys()}\n",
        "    pbar = tqdm(data_loader, desc=f'{mode.capitalize()}ing...')\n",
        "\n",
        "    for data in pbar:\n",
        "        images, labels = data['image'].to(device), data['label'].to(device)\n",
        "\n",
        "        with torch.set_grad_enabled(mode == 'train'):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = (outputs >= 0.0).float()\n",
        "            logs[mode]['predictions'] += preds.tolist()\n",
        "            logs[mode]['labels'] += labels.tolist()\n",
        "            logs[mode]['loss'] = total_loss / (logs[mode]['batch_idx'] + 1)\n",
        "\n",
        "            for metric_name, metric_func in metrics.items():\n",
        "                running_metrics[metric_name] += metric_func(labels.tolist(), preds.tolist())\n",
        "                logs['metrics'][mode + '_' + metric_name] = running_metrics[metric_name] / (logs[mode]['batch_idx'] + 1)\n",
        "\n",
        "            logs[mode]['batch_idx'] += 1\n",
        "            pbar.set_postfix({'loss': logs[mode]['loss'], **{metric_name: logs['metrics'][mode + '_' + metric_name] for metric_name in metrics.keys()}})\n",
        "\n",
        "            if mode == 'train':\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "def main_training_loop(model, criterion, optimizer, loader_train, loader_val, device, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        print(f'Epoch {epoch}:')\n",
        "        logs = initialize_logs_dict(loader_train, loader_val)\n",
        "        logs['epoch_num'] = epoch\n",
        "\n",
        "        run_epoch(model, criterion, optimizer, loader_train, device, 'train', logs)\n",
        "        run_epoch(model, criterion, optimizer, loader_val, device, 'val', logs)\n",
        "\n",
        "        print('train_loss: {:.4f} | val_loss: {:.4f} |'.format(logs['train']['loss'], logs['val']['loss']), end=' ')\n",
        "        print(\" | \".join(['{}: {:.4f}'.format(metric_name, metric_val) for metric_name, metric_val in logs['metrics'].items()]), end='\\n\\n')\n",
        "\n",
        "    run_epoch(model, criterion, optimizer, loader_test, device, 'val', logs)\n",
        "\n",
        "\n",
        "main_training_loop(model, criterion, optimizer, loader_train, loader_val, device, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BebWlEtK4R4M"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'model.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}